[
    {
        "label": "search_prompt",
        "importPath": "search",
        "description": "search",
        "isExtraImport": true,
        "detail": "search",
        "documentation": {}
    },
    {
        "label": "PyPDFLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "PyPDFLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain_text_splitters",
        "description": "langchain_text_splitters",
        "isExtraImport": true,
        "detail": "langchain_text_splitters",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain_text_splitters",
        "description": "langchain_text_splitters",
        "isExtraImport": true,
        "detail": "langchain_text_splitters",
        "documentation": {}
    },
    {
        "label": "GoogleGenerativeAIEmbeddings",
        "importPath": "langchain_google_genai",
        "description": "langchain_google_genai",
        "isExtraImport": true,
        "detail": "langchain_google_genai",
        "documentation": {}
    },
    {
        "label": "GoogleGenerativeAIEmbeddings",
        "importPath": "langchain_google_genai",
        "description": "langchain_google_genai",
        "isExtraImport": true,
        "detail": "langchain_google_genai",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain_core.documents",
        "description": "langchain_core.documents",
        "isExtraImport": true,
        "detail": "langchain_core.documents",
        "documentation": {}
    },
    {
        "label": "PGVector",
        "importPath": "langchain_postgres",
        "description": "langchain_postgres",
        "isExtraImport": true,
        "detail": "langchain_postgres",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.chat",
        "description": "src.chat",
        "peekOfCode": "def main():\n    chain = search_prompt()\n    if not chain:\n        print(\"Não foi possível iniciar o chat. Verifique os erros de inicialização.\")\n        return\n    pass\nif __name__ == \"__main__\":\n    main()",
        "detail": "src.chat",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.ingest-bk",
        "description": "src.ingest-bk",
        "peekOfCode": "def main():\n    chunks = splitter.split_documents(doc)\n    print(chunks[0])\n    embedding = GoogleGenerativeAIEmbeddings(\n        model=os.getenv(\"GOOGLE_EMBEDDING_MODEL\", \"models/embedding-001\")\n    )\n    preview_text = chunks[0].page_content[:20]\n    vector = embedding.embed_query(chunks[0].page_content[:20])\n    print(\"Preview:\")\n    print(preview_text, \"...\")",
        "detail": "src.ingest-bk",
        "documentation": {}
    },
    {
        "label": "PDF_PATH",
        "kind": 5,
        "importPath": "src.ingest-bk",
        "description": "src.ingest-bk",
        "peekOfCode": "PDF_PATH = os.getenv(\"PDF_PATH\", \"\")\nloader = PyPDFLoader(PDF_PATH)\ndoc = loader.load()\nsplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\nif not splitter:\n    raise SystemExit(0)\ndef main():\n    chunks = splitter.split_documents(doc)\n    print(chunks[0])\n    embedding = GoogleGenerativeAIEmbeddings(",
        "detail": "src.ingest-bk",
        "documentation": {}
    },
    {
        "label": "loader",
        "kind": 5,
        "importPath": "src.ingest-bk",
        "description": "src.ingest-bk",
        "peekOfCode": "loader = PyPDFLoader(PDF_PATH)\ndoc = loader.load()\nsplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\nif not splitter:\n    raise SystemExit(0)\ndef main():\n    chunks = splitter.split_documents(doc)\n    print(chunks[0])\n    embedding = GoogleGenerativeAIEmbeddings(\n        model=os.getenv(\"GOOGLE_EMBEDDING_MODEL\", \"models/embedding-001\")",
        "detail": "src.ingest-bk",
        "documentation": {}
    },
    {
        "label": "doc",
        "kind": 5,
        "importPath": "src.ingest-bk",
        "description": "src.ingest-bk",
        "peekOfCode": "doc = loader.load()\nsplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\nif not splitter:\n    raise SystemExit(0)\ndef main():\n    chunks = splitter.split_documents(doc)\n    print(chunks[0])\n    embedding = GoogleGenerativeAIEmbeddings(\n        model=os.getenv(\"GOOGLE_EMBEDDING_MODEL\", \"models/embedding-001\")\n    )",
        "detail": "src.ingest-bk",
        "documentation": {}
    },
    {
        "label": "splitter",
        "kind": 5,
        "importPath": "src.ingest-bk",
        "description": "src.ingest-bk",
        "peekOfCode": "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\nif not splitter:\n    raise SystemExit(0)\ndef main():\n    chunks = splitter.split_documents(doc)\n    print(chunks[0])\n    embedding = GoogleGenerativeAIEmbeddings(\n        model=os.getenv(\"GOOGLE_EMBEDDING_MODEL\", \"models/embedding-001\")\n    )\n    preview_text = chunks[0].page_content[:20]",
        "detail": "src.ingest-bk",
        "documentation": {}
    },
    {
        "label": "file_path",
        "kind": 2,
        "importPath": "src.ingest",
        "description": "src.ingest",
        "peekOfCode": "def file_path() -> str:\n    return os.getenv(\"PDF_PATH\", \"\")\ndef splitter() -> RecursiveCharacterTextSplitter:\n    return RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\ndef embedding() -> GoogleGenerativeAIEmbeddings:\n    return GoogleGenerativeAIEmbeddings(model=os.getenv(\"GOOGLE_EMBEDDING_MODEL\", \"\"))\ndef collection_name() -> str:\n    return os.getenv(\"PG_VECTOR_COLLECTION_NAME\", \"\")\ndef connection_url() -> str:\n    return os.getenv(\"DATABASE_URL\", \"\")",
        "detail": "src.ingest",
        "documentation": {}
    },
    {
        "label": "splitter",
        "kind": 2,
        "importPath": "src.ingest",
        "description": "src.ingest",
        "peekOfCode": "def splitter() -> RecursiveCharacterTextSplitter:\n    return RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\ndef embedding() -> GoogleGenerativeAIEmbeddings:\n    return GoogleGenerativeAIEmbeddings(model=os.getenv(\"GOOGLE_EMBEDDING_MODEL\", \"\"))\ndef collection_name() -> str:\n    return os.getenv(\"PG_VECTOR_COLLECTION_NAME\", \"\")\ndef connection_url() -> str:\n    return os.getenv(\"DATABASE_URL\", \"\")\ndef create_store() -> PGVector:\n    return PGVector(",
        "detail": "src.ingest",
        "documentation": {}
    },
    {
        "label": "embedding",
        "kind": 2,
        "importPath": "src.ingest",
        "description": "src.ingest",
        "peekOfCode": "def embedding() -> GoogleGenerativeAIEmbeddings:\n    return GoogleGenerativeAIEmbeddings(model=os.getenv(\"GOOGLE_EMBEDDING_MODEL\", \"\"))\ndef collection_name() -> str:\n    return os.getenv(\"PG_VECTOR_COLLECTION_NAME\", \"\")\ndef connection_url() -> str:\n    return os.getenv(\"DATABASE_URL\", \"\")\ndef create_store() -> PGVector:\n    return PGVector(\n        embeddings=embedding(),\n        collection_name=collection_name(),",
        "detail": "src.ingest",
        "documentation": {}
    },
    {
        "label": "collection_name",
        "kind": 2,
        "importPath": "src.ingest",
        "description": "src.ingest",
        "peekOfCode": "def collection_name() -> str:\n    return os.getenv(\"PG_VECTOR_COLLECTION_NAME\", \"\")\ndef connection_url() -> str:\n    return os.getenv(\"DATABASE_URL\", \"\")\ndef create_store() -> PGVector:\n    return PGVector(\n        embeddings=embedding(),\n        collection_name=collection_name(),\n        connection=connection_url(),\n        use_jsonb=True,",
        "detail": "src.ingest",
        "documentation": {}
    },
    {
        "label": "connection_url",
        "kind": 2,
        "importPath": "src.ingest",
        "description": "src.ingest",
        "peekOfCode": "def connection_url() -> str:\n    return os.getenv(\"DATABASE_URL\", \"\")\ndef create_store() -> PGVector:\n    return PGVector(\n        embeddings=embedding(),\n        collection_name=collection_name(),\n        connection=connection_url(),\n        use_jsonb=True,\n    )\ndef main():",
        "detail": "src.ingest",
        "documentation": {}
    },
    {
        "label": "create_store",
        "kind": 2,
        "importPath": "src.ingest",
        "description": "src.ingest",
        "peekOfCode": "def create_store() -> PGVector:\n    return PGVector(\n        embeddings=embedding(),\n        collection_name=collection_name(),\n        connection=connection_url(),\n        use_jsonb=True,\n    )\ndef main():\n    # Carrega o PDF para ler seu conteúdo\n    pdfLoader = PyPDFLoader(file_path())",
        "detail": "src.ingest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.ingest",
        "description": "src.ingest",
        "peekOfCode": "def main():\n    # Carrega o PDF para ler seu conteúdo\n    pdfLoader = PyPDFLoader(file_path())\n    documents = pdfLoader.load()\n    # Utiliza o recursive text splitter para quebrar o documento em chunks\n    chunks = splitter().split_documents(documents)\n    # Aplica uma limpeza de metadados vazios ou nulos\n    enrich_document = [\n        Document(\n            page_content=document.page_content,",
        "detail": "src.ingest",
        "documentation": {}
    },
    {
        "label": "search_prompt",
        "kind": 2,
        "importPath": "src.search",
        "description": "src.search",
        "peekOfCode": "def search_prompt(question=None):\n    pass",
        "detail": "src.search",
        "documentation": {}
    },
    {
        "label": "PROMPT_TEMPLATE",
        "kind": 5,
        "importPath": "src.search",
        "description": "src.search",
        "peekOfCode": "PROMPT_TEMPLATE = \"\"\"\nCONTEXTO:\n{contexto}\nREGRAS:\n- Responda somente com base no CONTEXTO.\n- Se a informação não estiver explicitamente no CONTEXTO, responda:\n  \"Não tenho informações necessárias para responder sua pergunta.\"\n- Nunca invente ou use conhecimento externo.\n- Nunca produza opiniões ou interpretações além do que está escrito.\nEXEMPLOS DE PERGUNTAS FORA DO CONTEXTO:",
        "detail": "src.search",
        "documentation": {}
    }
]